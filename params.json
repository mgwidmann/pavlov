{"name":"Pavlov","tagline":"A BDD framework for your Elixir projects","body":"[![Build Status](https://travis-ci.org/sproutapp/pavlov.svg?branch=master)](https://travis-ci.org/sproutapp/pavlov)\r\n[![Inline docs](http://inch-ci.org/github/sproutapp/pavlov.svg?branch=master&style=flat)](http://inch-ci.org/github/sproutapp/pavlov)\r\n\r\nPavlov provides a rich, expressive syntax for you to develop your unit tests against. Think of it as RSpec's little Elixir-loving brother.\r\n\r\nPavlov is an abstraction built on top of the excellent ExUnit, Elixir's standard testing library, so all of its standard features are still supported.\r\n\r\nHere's a short and sweet example of Pavlov in action:\r\n\r\n```elixir\r\ndefmodule OrderSpec do\r\n  use Pavlov.Case, async: true\r\n  import Pavlov.Syntax.Expect\r\n\r\n  describe \".sum\" do\r\n    context \"When the Order has items\" do\r\n      let :order do\r\n        %Order{items: [\r\n          {\"burger\", 10.0}\r\n          {\"fries\", 5.2}\r\n        ]}\r\n      end\r\n\r\n      it \"sums the prices of its items\" do\r\n        expect Order.sum(order) |> to_eq 15.2\r\n      end\r\n    end\r\n  end\r\nend\r\n```\r\n\r\n## Table Of Contents\r\n\r\n- [Usage](#usage)\r\n- [Describe and Context](#describe-and-context)\r\n- [Let](#let)\r\n- [Expects syntax](#expects-syntax)\r\n- [Included Matchers](#included-matchers)\r\n- [Callbacks](#callbacks)\r\n  - [before(:each)](#beforeeach)\r\n  - [before(:all)](#beforeall)\r\n- [Mocking](#mocking)\r\n\t- [Mocks with arguments](#mocks-with-arguments)\r\n- [Skipping tests](#skipping-tests)\r\n\t- [xit](#xit)\r\n\t- [xdescribe/xcontext](#xdescribexcontext)\r\n- [Development](#development)\r\n\t- [Running the tests](#running-the-tests)\r\n\t- [Building the docs](#building-the-docs)\r\n- [Contributing](#contributing)\r\n\r\n## Usage\r\nAdd Pavlov as a dependency in your `mix.exs` file:\r\n\r\n```elixir\r\ndefp deps do\r\n  [{:pavlov, \">= 0.1.0\", only: :test}]\r\nend\r\n```\r\n\r\nAfter you are done, run `mix deps.get` in your shell to fetch the dependencies.\r\nTo start execution of your Pavlov tests, add the following to your 'test/test_helper.exs':\r\n\r\n```elixir\r\nPavlov.start\r\n```\r\n\r\nAfterwards, running `mix test` in your shell will run all test suites.\r\n\r\n## Describe and Context\r\nYou may use the `describe` and `context` constructs to group tests together in a logical way. Although `context` is just an alias for `describe`, you may use it to add some extra meaning to your tests, ie. you can use `contexts` within a `described` module function to simulate different conditions under which your function should work.\r\n\r\n## Let\r\nYou can use `let` to define memoized helper methods for your tests. The returning value is cached across all invocations. 'let' is lazily-evaluated, meaning that its body is not evaluated until the first time the method is invoked.\r\n\r\n```elixir\r\nlet :order do\r\n  %Order{items: [\r\n    {\"burger\", 10.0}\r\n    {\"fries\", 5.2}\r\n  ]}\r\nend\r\n```\r\n\r\n## Expects syntax\r\n\r\nYou may use the regular ExUnit `assert` syntax if you wish, but Pavlov includes\r\nan `expect` syntax that makes your tests more readable.\r\n\r\nIf you wish to use this syntax, simply import the `Pavlov.Syntax.Expect` at the\r\nbeginning of your Test module:\r\n\r\n```elixir\r\ndefmodule MyTest do\r\n  use Pavlov.Case, async: true\r\n  import Pavlov.Syntax.Expect\r\n  #...\r\nend\r\n```\r\n\r\nAll core matchers are supported under both syntaxes.\r\n\r\n## Included Matchers\r\n\r\nWhen using the `expects` syntax, all matchers have negative counterparts, ie:\r\n```elixir\r\nexpect 1 |> not_to_eq 2\r\nexpect(1 > 5) |> not_to_be_true\r\n```\r\n\r\nVisit the [Pavlov Wiki](https://github.com/sproutapp/pavlov/wiki/Included-Matchers)\r\nto learn more about all of the core matchers available for your tests.\r\n\r\n## Callbacks\r\nFor now, Pavlov only supports callbacks that run before test cases. [ExUnit's\r\n`on_exit` callback](http://elixir-lang.org/docs/stable/ex_unit/ExUnit.Callbacks.html#on_exit/2) is still fully supported though, and may be used normally inside your `before` callbacks.\r\n\r\n### before(:each)\r\nRuns the specified code before every test case.\r\n\r\n```elixir\r\ndescribe \"before :each\" do\r\n  before :each do\r\n    IO.puts \"A test is about to start\"\r\n    :ok\r\n  end\r\n\r\n  it \"does something\" do\r\n    #...\r\n  end\r\n\r\n  it \"does something else\" do\r\n    #...\r\n  end\r\nend\r\n```\r\n\r\nIn this case, `\"A test is about to start\"` is printed twice to the console.\r\n\r\n### before(:all)\r\nRuns the specified code once before any tests run.\r\n\r\n```elixir\r\ndescribe \"before :all\" do\r\n  before :all do\r\n    IO.puts \"This suite is about to run\"\r\n    :ok\r\n  end\r\n\r\n  it \"does something\" do\r\n    #...\r\n  end\r\n\r\n  it \"does something else\" do\r\n    #...\r\n  end\r\nend\r\n```\r\nIn this case, `\"This suite is about to run\"` is printed once to the console.\r\n\r\n## Mocking\r\nPavlov provides facilities to mock functions in your Elixir modules. This is\r\nachieved using [Meck](https://github.com/eproxus/meck), an erlang mocking tool.\r\n\r\nHere's a simple example using [HTTPotion](https://github.com/myfreeweb/httpotion):\r\n\r\n```elixir\r\nbefore :each do\r\n  allow HTTPotion |> to_receive(get: fn(url) -> \"<html></html>\" end)\r\nend\r\n\r\nit \"gets a page\" do\r\n  result = HTTPotion.get(\"http://example.com\")\r\n\r\n  expect HTTPotion |> to_have_received :get\r\n  expect result |> to_eq \"<html></html>\"\r\nend\r\n```\r\n\r\nIf you want the mock to retain all other functions in the original module,\r\nthen you will need to pass the `opts` `List` argument to the `allow` function\r\nand include the `:passthrough` value. The `allow` function specifies a default\r\n`opts` `List` that includes the `:no_link` value. This value should be included\r\nin the `List` as it ensures that the mock (which is linked to the creating\r\nprocess) will unload automatically when a crash occurs.\r\n\r\n```elixir\r\nbefore :each do\r\n  allow(HTTPotion, [:no_link, :passthrough]) |> to_receive(get: fn(url) -> \"<html></html>\" end)\r\nend\r\n```\r\n\r\nExpectations on mocks also work using `asserts` syntax via the `called` matcher:\r\n\r\n```elixir\r\nbefore :each do\r\n  allow HTTPotion |> to_receive(get: fn(url) -> \"<html></html>\" end)\r\nend\r\n\r\nit \"gets a page\" do\r\n  HTTPotion.get(\"http://example.com\")\r\n\r\n  assert called HTTPotion.get\r\nend\r\n```\r\n\r\n### Mocks with arguments\r\nYou can also perform assertions on what arguments were passed to a mocked\r\nmethod:\r\n\r\n```elixir\r\nbefore :each do\r\n  allow HTTPotion |> to_receive(get: fn(url) -> \"<html></html>\" end)\r\nend\r\n\r\nit \"gets a page\" do\r\n  HTTPotion.get(\"http://example.com\")\r\n\r\n  expect HTTPotion |> to_have_received :get |> with \"http://example.com\"\r\nend\r\n```\r\n\r\nIn `asserts` syntax:\r\n\r\n```elixir\r\nbefore :each do\r\n  allow HTTPotion |> to_receive (get: fn(url) -> url end )\r\nend\r\n\r\nit \"gets a page\" do\r\n  HTTPotion.get(\"http://example.com\")\r\n\r\n  assert called HTTPotion.get(\"http://example.com\")\r\nend\r\n```\r\n\r\n## Skipping tests\r\nPavlov runs with the `--exclude pending:true` configuration by default, which\r\nmeans that tests tagged with `:pending` will not be run.\r\n\r\nPavlov offers several convenience methods to skip your tests, BDD style:\r\n\r\n### xit\r\nMarks a specific test as pending and will not run it.\r\n\r\n```elixir\r\nxit \"does not run\" do\r\n  # This will never run\r\nend\r\n```\r\n\r\n### xdescribe/xcontext\r\nMarks a group of tests as pending and will not run them. Just as `describe`\r\nand `context`, `xdescribe` and `xcontext` are analogous.\r\n\r\n```elixir\r\nxdescribe \"A pending group\" do\r\n  it \"does not run\" do\r\n    # This will never run\r\n  end\r\n\r\n  it \"does not run either\" do\r\n    # This will never run either\r\n  end\r\nend\r\n```\r\n\r\n## Development\r\n\r\nAfter cloning the repo, make sure to download all dependencies using `mix deps.get`.\r\nPavlov is tested using Pavlov itself, so the general philosophy is to simply write a test using a given feature until it passes.\r\n\r\n### Running the tests\r\nSimply run `mix test`\r\n\r\n### Building the docs\r\nRun `MIX_ENV=docs mix docs`. The resulting HTML files will be output to the `docs` folder.\r\n\r\n## Contributing\r\n\r\n1. Fork it ( https://github.com/sproutapp/pavlov/fork )\r\n2. Create your feature branch (`git checkout -b my-new-feature`)\r\n3. Commit your changes (`git commit -am 'Add some feature'`)\r\n4. Push to the branch (`git push origin my-new-feature`)\r\n5. Create a new Pull Request\r\n","google":"UA-5722833-4","note":"Don't delete this file! It's used internally to help with page regeneration."}